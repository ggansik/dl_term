{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#from Tacotron import Tacotron\n",
    "from text import text_to_sequence, symbols\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighwayNet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: (batch_size, Channel, Length)\n",
    "        input: (# of batch, seq_length, 128(input feature))\n",
    "        h * t + x * (1. - t)\n",
    "        output: (# of batch, seq_length, 128(output feature))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HighwayNet, self).__init__()\n",
    "        \n",
    "        self.H = nn.Linear(128, 128)\n",
    "        self.T = nn.Linear(128, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.H(x))\n",
    "        t = torch.sigmoid(self.T(x))\n",
    "        \n",
    "        output = h * t + x * (1. - t)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class EncoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: prenet output\n",
    "        input: (batch_size, channels, seq_length)\n",
    "        Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "        output: (seq_length, batch_size, 2 * hidden_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, K=16):\n",
    "        super(EncoderCBHG, self).__init__()\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(128, 128, k, stride=1, padding=k//2)\n",
    "            for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 128, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(128, 128, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet() for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            raw_input: (# of batch, seq_length, 128(output feature))\n",
    "            input: (batch_size, channels, seq_length)\n",
    "            Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "            output: (seq_length, batch_size, 2 * hidden_size)\n",
    "        \"\"\"\n",
    "        x = x.T(1, 2)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        stacked = []\n",
    "        for conv1d in conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)))\n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn(self.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn(self.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        y = y.T(1, 2)\n",
    "        for layer in self.highwayNet:\n",
    "            y = self.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        y = y.T(0, 1)\n",
    "        y, _ = self.GRU(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: encoder input\n",
    "        input: (# of batch, seq_length, 128(output feature))\n",
    "        FC(Dense) - ReLU - Dropout - FC - ReLU - Dropout\n",
    "        output: (# of batch, seq_length, 128(output feature))\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Prenet, self).__init__()\n",
    "        self.layer = nn.ModuleList(\n",
    "            [nn.Linear(256, 256)\n",
    "            ,nn.Linear(256, 128)]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for layer in self.layer:\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        prenet - CBHG\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.prenet = Prenet()\n",
    "        self.cbhg = EncoderCBHG()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cbhg(self.prenet(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayNet(nn.Module):\n",
    "    \"\"\"\n",
    "    h * t + x * (1. - t)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HighwayNet, self).__init__()\n",
    "        \n",
    "        self.H = nn.Linear(128, 128)\n",
    "        self.T = nn.Linear(128, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.H(x))\n",
    "        t = torch.sigmoid(self.T(x))\n",
    "        \n",
    "        output = h * t + x * (1. - t)\n",
    "        return output\n",
    "\n",
    "class DecoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, K=8):\n",
    "        super(DecoderCBHG, self).__init__()\n",
    "        #conv1d: (batch_size, Channel, Length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(128, 128, k, stride=1, padding=k//2)\n",
    "            for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 256, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(256, 80, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet() for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = x.T(1, 2) # Shape: (batch_size, channels, seq_length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        stacked = []\n",
    "        for conv1d in conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)))\n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #shape: \n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn(self.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn(self.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        for layer in self.highwayNet:\n",
    "            y = self.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        y, _ = self.GRU(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "             \n",
    "class AttentionWrapper(nn.Module):\n",
    "    def __init__(self, rnn, use_attention):\n",
    "        super(AttentionWrapper, self).__init__()\n",
    "        self.rnn_cell = rnn\n",
    "        self.attention = use_attention\n",
    "        self.projection_for_decoderRNN = nn.Linear(512, 256, bias=False)\n",
    "    def forward(self, memory, decoder_input, cell_hidden):\n",
    "        \"\"\"\n",
    "        memory = (batch_size, encoder_T, dim)\n",
    "        decoder_input = (batch_size, dim)\n",
    "        cell_hidden (previous time step cell state) = (batch, dim)\n",
    "        \"\"\"\n",
    "        batch_size = memory.size(0)\n",
    "        #cell_input = torch.cat((decoder_input, prev_attention), -1) -- why do we have to concat?\n",
    "        cell_input = decoder_input\n",
    "        query = self.rnn_cell(cell_input, cell_hidden)\n",
    "        #feed into attention\n",
    "        attention_weights = self.attention(query, memory)\n",
    "        #make context vector\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        context = torch.bmm(attention_weights.view(batch_size, 1, -1), memory).squeeze(1)\n",
    "        out = self.projection_for_decoderRNN(torch.cat([context, query],dim=-1))\n",
    "        return out, query, attention_weights\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.v = nn.Linear(256,1,bias=False)\n",
    "        self.query_layer = nn.Linear(256,256,bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, query, memory):\n",
    "        \"\"\"\n",
    "        query : (batch, 1 ,dim)\n",
    "        \"\"\"\n",
    "        if query.dim() == 2:\n",
    "            query = query.unsqueeze(1)\n",
    "        attention_weight = self.v(self.tanh(self.query_layer(query) + memory))\n",
    "        return attention_weight\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, spect_dim, r=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.spect_dim = spect_dim\n",
    "        self.r = r\n",
    "        self.prenet = Prenet()\n",
    "        self.attention_RNN = AttentionWrapper(nn.GRUCell(input_size=256, hidden_size =256), BahdanauAttention())\n",
    "        self.decoder_RNN = nn.ModuleList(\n",
    "                            [nn.GRUCell(input_size=256,hidden_size=256) for _ in range(2)])\n",
    "        self.spectro_layer = nn.Linear(256,spect_dim*r,bias=False)\n",
    "        self.epsilon = 0.2\n",
    "        self.maximum_step = 1000\n",
    "        return\n",
    "    \n",
    "    def forward(self, memory, target=None):\n",
    "        \"\"\"\n",
    "        if training time, input is given, else input is decoder outputs\n",
    "        input : \n",
    "            memory (encoder_output) = (batch_size, encoder_T, char_dim)\n",
    "            decoder_input = (batch_size, decoder_T, dim)\n",
    "        output:\n",
    "            \n",
    "        \"\"\"\n",
    "        batch_size = memory.size(0)\n",
    "        test = target is None\n",
    "        decoder_T = 0\n",
    "        \n",
    "        #train data를 r 단위로 묶어준 후 T의 크기를 바꾸어준다.\n",
    "        if not test:\n",
    "            target = target.view(batch_size, target.size(1) // r, -1)\n",
    "            decoder_T = target.size(1)\n",
    "            target = target.transpose(0,1) #for parallelization\n",
    "            \n",
    "        #2단계 decoderRNN 값 저장할 array\n",
    "        decoderRNN_output = [memory.zero_() for _ in range(len(decoder_RNN))] \n",
    "        \n",
    "        #<GO> Frame\n",
    "        current_input = torch.zero([batch_size, self.r*self.spect_dim])\n",
    "        t = 0\n",
    "        targets = []\n",
    "        attention_weights = []\n",
    "        \n",
    "        while (True):\n",
    "            t = t + 1\n",
    "            #prenet\n",
    "            #(B, spect_dim * r)\n",
    "            prenet_output = self.prenet(current_input)\n",
    "            \n",
    "            #attention\n",
    "            #(B, 256)\n",
    "            attention_output, cell_hidden, attention_weight = self.attention(memory, prenet_output, cell_hidden)\n",
    "            \n",
    "            #decoder\n",
    "            #(B, spect_dim * r)\n",
    "            for idx in range(2):\n",
    "                decoderRNN_output[idx] = self.decoder_RNN[idx](attention_output, decoder_output[idx])\n",
    "                decoderRNN_output[idx] += attention_output\n",
    "                attention_output = decoder_output[idx]\n",
    "            \n",
    "            #projection\n",
    "            targetchar =self.spectro_layer(attention_output)\n",
    "            targets += [targetchar]\n",
    "            attention_weights += [attention_weight]\n",
    "            \n",
    "            #check if this target is the end\n",
    "            if test:\n",
    "                if t > 1 and (targetchar<=self.epsilon).all(): break\n",
    "                if t > self.maximum_step: \n",
    "                    print(\"ERROR : Not converge\")\n",
    "                    break\n",
    "            else:\n",
    "                if t >= decoder_T:\n",
    "                    break\n",
    "                    \n",
    "            #change current input\n",
    "            if test:\n",
    "                current_input = targets[-1]\n",
    "            else:\n",
    "                current_input = target[t-1]\n",
    "        \n",
    "        attention_weights = torch.stack(attention_weights).transpose(0,1)\n",
    "        outputs = torch.stack(outputs).transpose(0,1).contiguous()\n",
    "        return outputs, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad(seq, max_len):\n",
    "    return np.pad(seq, (0, max_len - len(seq)),\n",
    "                  mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def test_taco():\n",
    "    B, T_out, D_out = 2, 400, 80\n",
    "    r = 5\n",
    "    T_encoder = T_out // r\n",
    "\n",
    "    texts = [\"Thank you very much.\", \"Hello\"]\n",
    "    seqs = [np.array(text_to_sequence(\n",
    "        t, [\"english_cleaners\"]), dtype=np.int) for t in texts]\n",
    "    input_lengths = np.array([len(s) for s in seqs])\n",
    "    max_len = np.max(input_lengths)\n",
    "    seqs = np.array([_pad(s, max_len) for s in seqs])\n",
    "\n",
    "    x = torch.LongTensor(seqs)\n",
    "    y = torch.rand(B, T_out, D_out)\n",
    "    x = Variable(x)\n",
    "    y = Variable(y)\n",
    "\n",
    "    model = Tacotron(vocab_num=len(symbols))\n",
    "\n",
    "    print(\"Encoder input shape: \", x.size())\n",
    "    print(\"Decoder input shape: \", y.size())\n",
    "    a, b, c = model(x, y, input_lengths=input_lengths)\n",
    "    print(\"Mel shape:\", a.size())\n",
    "    print(\"Linear shape:\", b.size())\n",
    "    print(\"Attention shape:\", c.size())\n",
    "\n",
    "    assert c.size() == (B, T_encoder, max_len)\n",
    "\n",
    "    # Test greddy decoding\n",
    "    a, b, c = model(x, input_lengths=input_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-9bd1e398ab7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_taco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-52-64adeb93b0ea>\u001b[0m in \u001b[0;36mtest_taco\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTacotron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Encoder input shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\dl_term\\networks\\Tacotron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab_num, input_dim, spect_dim)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEncoderCBHG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;31m#-----------------Conv1Dbank-------------------#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         self.conv1dBank = nn.ModuleList(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "test_taco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
