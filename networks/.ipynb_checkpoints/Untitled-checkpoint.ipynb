{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#from Tacotron import Tacotron\n",
    "from text import text_to_sequence, symbols\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighwayNet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: (batch_size, Channel, Length)\n",
    "        input: (# of batch, seq_length, 128(input feature))\n",
    "        h * t + x * (1. - t)\n",
    "        output: (# of batch, seq_length, 128(output feature))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HighwayNet, self).__init__()\n",
    "        \n",
    "        self.H = nn.Linear(128, 128)\n",
    "        self.T = nn.Linear(128, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.H(x))\n",
    "        t = torch.sigmoid(self.T(x))\n",
    "        \n",
    "        output = h * t + x * (1. - t)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class EncoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: prenet output\n",
    "        input: (batch_size, channels, seq_length)\n",
    "        Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "        output: (seq_length, batch_size, 2 * hidden_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, K=16):\n",
    "        super(EncoderCBHG, self).__init__()\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(128, 128, k, stride=1, padding=k//2)\n",
    "            for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 128, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(128, 128, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet() for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            raw_input: (# of batch, seq_length, 128(output feature))\n",
    "            input: (batch_size, channels, seq_length)\n",
    "            Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "            output: (seq_length, batch_size, 2 * hidden_size)\n",
    "        \"\"\"\n",
    "        x = x.transpose(1, 2)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        temp = x.size(-1)\n",
    "        stacked = []\n",
    "        for conv1d in self.conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)[:, :, :temp]))\n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)[:, :, :temp]\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn(F.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn(self.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        y = y.transpose(1, 2)\n",
    "        for layer in self.highwayNet:\n",
    "            y = F.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        y, _ = self.GRU(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: encoder input\n",
    "        input: (# of batch, seq_length, 128(output feature))\n",
    "        FC(Dense) - ReLU - Dropout - FC - ReLU - Dropout\n",
    "        output: (# of batch, seq_length, 128(output feature))\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(Prenet, self).__init__()\n",
    "        self.layer = nn.ModuleList(\n",
    "            [nn.Linear(in_dim, 256)\n",
    "            ,nn.Linear(256, 128)]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for layer in self.layer:\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        prenet - CBHG\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.prenet = Prenet(256)\n",
    "        self.cbhg = EncoderCBHG()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cbhg(self.prenet(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayNet(nn.Module):\n",
    "    \"\"\"\n",
    "    h * t + x * (1. - t)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HighwayNet, self).__init__()\n",
    "        \n",
    "        self.H = nn.Linear(128, 128)\n",
    "        self.T = nn.Linear(128, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.H(x))\n",
    "        t = torch.sigmoid(self.T(x))\n",
    "        \n",
    "        output = h * t + x * (1. - t)\n",
    "        return output\n",
    "\n",
    "class DecoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, K=8):\n",
    "        super(DecoderCBHG, self).__init__()\n",
    "        #conv1d: (batch_size, Channel, Length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(128, 128, k, stride=1, padding=k//2)\n",
    "            for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 256, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(256, 80, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet() for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = x.transpose(1, 2) # Shape: (batch_size, channels, seq_length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        temp = x.size(-1)\n",
    "        stacked = []\n",
    "        for conv1d in self.conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)[:, :, :temp]))\n",
    "        \n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #shape: \n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)[:, :, :temp]\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn(F.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn(F.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        for layer in self.highwayNet:\n",
    "            y = self.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        y, _ = self.GRU(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "             \n",
    "class AttentionWrapper(nn.Module):\n",
    "    def __init__(self, rnn, use_attention):\n",
    "        super(AttentionWrapper, self).__init__()\n",
    "        self.rnn_cell = rnn\n",
    "        self.attention = use_attention\n",
    "        self.projection_for_decoderRNN = nn.Linear(512, 256, bias=False)\n",
    "    def forward(self, memory, decoder_input, cell_hidden):\n",
    "        \"\"\"\n",
    "        memory = (batch_size, encoder_T, dim)\n",
    "        decoder_input = (batch_size, dim)\n",
    "        cell_hidden (previous time step cell state) = (batch, dim)\n",
    "        \"\"\"\n",
    "        batch_size = memory.size(0)\n",
    "        #cell_input = torch.cat((decoder_input, prev_attention), -1) -- why do we have to concat?\n",
    "        cell_input = decoder_input\n",
    "        query = self.rnn_cell(cell_input, cell_hidden)\n",
    "        #feed into attention\n",
    "        attention_weights = self.attention(query, memory)\n",
    "        #make context vector\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        context = torch.bmm(attention_weights.view(batch_size, 1, -1), memory).squeeze(1)\n",
    "        out = self.projection_for_decoderRNN(torch.cat([context, query],dim=-1))\n",
    "        return out, query, attention_weights\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.v = nn.Linear(256,1,bias=False)\n",
    "        self.query_layer = nn.Linear(256,256,bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, query, memory):\n",
    "        \"\"\"\n",
    "        query : (batch, 1 ,dim)\n",
    "        \"\"\"\n",
    "        if query.dim() == 2:\n",
    "            query = query.unsqueeze(1)\n",
    "        attention_weight = self.v(self.tanh(self.query_layer(query) + memory))\n",
    "        return attention_weight\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, spect_dim, r=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.spect_dim = spect_dim\n",
    "        self.r = r\n",
    "        self.prenet = Prenet(r*spect_dim)\n",
    "        self.attention_RNN = AttentionWrapper(nn.GRUCell(input_size=128, hidden_size =256), BahdanauAttention())\n",
    "        self.decoderRNN = nn.ModuleList(\n",
    "                            [nn.GRUCell(input_size=256,hidden_size=256) for _ in range(2)])\n",
    "        self.spectro_layer = nn.Linear(256,spect_dim*r,bias=False)\n",
    "        self.epsilon = 0.2\n",
    "        self.maximum_step = 1000\n",
    "        return\n",
    "    \n",
    "    def forward(self, memory, target=None):\n",
    "        \"\"\"\n",
    "        if training time, input is given, else input is decoder outputs\n",
    "        input : \n",
    "            memory (encoder_output) = (batch_size, encoder_T, char_dim)\n",
    "            decoder_input = (batch_size, decoder_T, dim)\n",
    "        output:\n",
    "            \n",
    "        \"\"\"\n",
    "        print(memory.shape)\n",
    "        batch_size = memory.size(0)\n",
    "        test = target is None\n",
    "        decoder_T = 0\n",
    "        \n",
    "        #train data를 r 단위로 묶어준 후 T의 크기를 바꾸어준다.\n",
    "        if not test:\n",
    "            target = target.view(batch_size, target.size(1) // self.r, -1)\n",
    "            decoder_T = target.size(1)\n",
    "            target = target.transpose(0,1) #for parallelization\n",
    "            \n",
    "        #2단계 decoderRNN 값 저장할 array\n",
    "        decoderRNN_output = [torch.zeros([batch_size, 256]) for _ in range(len(self.decoderRNN))] \n",
    "        cell_hidden = torch.zeros([batch_size, 256])\n",
    "        \n",
    "        #<GO> Frame\n",
    "        #print(self.r * self.spect_dim)\n",
    "        current_input = torch.zeros([batch_size, self.r*self.spect_dim])\n",
    "        t = 0\n",
    "        targets = []\n",
    "        attention_weights = []\n",
    "        \n",
    "        while (True):\n",
    "            t = t + 1\n",
    "            \n",
    "            #prenet\n",
    "            #(B, spect_dim * r)\n",
    "            #print(current_input.size())\n",
    "            prenet_output = self.prenet(current_input)\n",
    "            print(prenet_output.size())\n",
    "            #attention\n",
    "            #(B, 256)\n",
    "            attention_output, cell_hidden, attention_weight = self.attention_RNN(memory, prenet_output, cell_hidden)\n",
    "            \n",
    "            #decoder\n",
    "            #(B, spect_dim * r)\n",
    "            print(attention_output.size())\n",
    "            print(decoderRNN_output[0].size())\n",
    "            for idx in range(2):\n",
    "                decoderRNN_output[idx] = self.decoderRNN[idx](attention_output, decoderRNN_output[idx])\n",
    "                decoderRNN_output[idx] += attention_output\n",
    "                attention_output = decoderRNN_output[idx]\n",
    "            \n",
    "            #projection\n",
    "            targetchar =self.spectro_layer(attention_output)\n",
    "            targets += [targetchar]\n",
    "            attention_weights += [attention_weight]\n",
    "            \n",
    "            #check if this target is the end\n",
    "            if test:\n",
    "                if t > 1 and (targetchar<=self.epsilon).all(): break\n",
    "                if t > self.maximum_step: \n",
    "                    print(\"ERROR : Not converge\")\n",
    "                    break\n",
    "            else:\n",
    "                if t >= decoder_T:\n",
    "                    break\n",
    "                    \n",
    "            #change current input\n",
    "            if test:\n",
    "                current_input = targets[-1]\n",
    "            else:\n",
    "                current_input = target[t-1]\n",
    "        \n",
    "        attention_weights = torch.stack(attention_weights).transpose(0,1)\n",
    "        targets = torch.stack(targets).transpose(0,1).contiguous()\n",
    "        return targets, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessing(nn.Module):\n",
    "    \"\"\"\n",
    "    make post processing data\n",
    "    input : (B, decoder.T, spect_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, spect_dim):\n",
    "        super(PostProcessing, self).__init__()\n",
    "        self.postcbhg = DecoderCBHG(K=8)\n",
    "        self.linear = nn.Linear(spect_dim * 2, 1025)\n",
    "    def forward(self, batch_size, data):\n",
    "        \"\"\"\n",
    "            make data shape (B, -1, 80)\n",
    "        \"\"\"\n",
    "        data = data.view(batch_size, -1, 80)\n",
    "        output = self.postcbhg(data)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class Tacotron(nn.Module):\n",
    "    def __init__(self, vocab_num, input_dim=256, spect_dim=80):\n",
    "        super(Tacotron, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.spect_dim = spect_dim\n",
    "        self.embedding = nn.Embedding(vocab_num, input_dim) #embedding dimension\n",
    "        self.embedding.weight.data.normal_(0,0.3)\n",
    "        self.Encoder = Encoder()\n",
    "        self.Decoder = Decoder(spect_dim, r=2) #write input_dimension\n",
    "        self.Postprocessing = PostProcessing(spect_dim)\n",
    "    def forward(self, inputs, spect_targets=None, r= 5):\n",
    "        \"\"\"\n",
    "        make total model!\n",
    "        input : (B, encoder.T, in_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        batch_size = inputs.size(0)\n",
    "        memory = self.embedding(inputs)\n",
    "        \n",
    "        #encoding\n",
    "        #(B, encoder.T, input_dim)\n",
    "        memory = self.Encoder(memory)\n",
    "\n",
    "        #decoding\n",
    "        #(B, encoder.T, mel_dim * r)\n",
    "        decoder_output, attention_weights = self.Decoder(memory, spect_targets)\n",
    "        \n",
    "        #postprocessing\n",
    "        #(B, decoder.T, 1025)\n",
    "        decoder_output = decoder_output.view(B, -1, self.spect_dim)\n",
    "        wav_output = self.PostProcessing(batch_size, decoder_output)\n",
    "        \n",
    "        return decoder_output, wav_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad(seq, max_len):\n",
    "    return np.pad(seq, (0, max_len - len(seq)),\n",
    "                  mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def test_taco():\n",
    "    B, T_out, D_out = 2, 400, 80\n",
    "    r = 5\n",
    "    T_encoder = T_out // r\n",
    "\n",
    "    texts = [\"Thank you very much.\", \"Hello\"]\n",
    "    seqs = [np.array(text_to_sequence(\n",
    "        t, [\"english_cleaners\"]), dtype=np.int) for t in texts]\n",
    "    input_lengths = np.array([len(s) for s in seqs])\n",
    "    max_len = np.max(input_lengths)\n",
    "    seqs = np.array([_pad(s, max_len) for s in seqs])\n",
    "\n",
    "    x = torch.LongTensor(seqs)\n",
    "    y = torch.rand(B, T_out, D_out)\n",
    "    x = Variable(x)\n",
    "    y = Variable(y)\n",
    "\n",
    "    model = Tacotron(vocab_num=len(symbols))\n",
    "\n",
    "    print(\"Encoder input shape: \", x.size())\n",
    "    print(\"Decoder input shape: \", y.size())\n",
    "    a, b, c = model(x, spect_targets=y)\n",
    "    print(\"Mel shape:\", a.size())\n",
    "    print(\"Linear shape:\", b.size())\n",
    "    print(\"Attention shape:\", c.size())\n",
    "\n",
    "    assert c.size() == (B, T_encoder, max_len)\n",
    "\n",
    "    # Test greddy decoding\n",
    "    a, b, c = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape:  torch.Size([2, 21])\n",
      "Decoder input shape:  torch.Size([2, 400, 80])\n",
      "torch.Size([2, 21, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-9bd1e398ab7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_taco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-143-990d3c042df5>\u001b[0m in \u001b[0;36mtest_taco\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Encoder input shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Decoder input shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspect_targets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mel shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Linear shape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-142-67a5af51c19c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, spect_targets, r)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m#(B, encoder.T, mel_dim * r)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mdecoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspect_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m#postprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "test_taco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
