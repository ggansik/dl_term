{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#from Tacotron import Tacotron\n",
    "from text import text_to_sequence, symbols\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HighwayNet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: (batch_size, Channel, Length)\n",
    "        input: (# of batch, seq_length, input feature)\n",
    "        h * t + x * (1. - t)\n",
    "        output: (# of batch, seq_length, output feature)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(HighwayNet, self).__init__()\n",
    "        \n",
    "        self.H = nn.Linear(128, 128)\n",
    "        self.T = nn.Linear(128, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.H(x))\n",
    "        t = torch.sigmoid(self.T(x))\n",
    "        output = h * t + x * (1. - t)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class EncoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: prenet output\n",
    "        input: (batch_size, channels, seq_length)\n",
    "        Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "        output: (seq_length, batch_size, 2 * hidden_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, K=16):\n",
    "        super(EncoderCBHG, self).__init__()\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(128, 128, k, stride=1, padding=k//2)\n",
    "            for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 128, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(128, 128, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet(128) for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            raw_input: (# of batch, seq_length, 128(output feature))\n",
    "            input: (batch_size, channels, seq_length)\n",
    "            Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "            output: (seq_length, batch_size, 2 * hidden_size)\n",
    "        \"\"\"\n",
    "        x = x.transpose(1, 2)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        temp = x.size(-1)\n",
    "        stacked = []\n",
    "        for conv1d in self.conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)[:, :, :temp]))\n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)[:, :, :temp]\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn(F.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn(self.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        y = y.transpose(1, 2)\n",
    "        for layer in self.highwayNet:\n",
    "            y = F.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        print(\"before encoder gru\", end=\" \")\n",
    "        print(y.size())\n",
    "        y, _ = self.GRU(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    \"\"\"\n",
    "        raw_input: encoder input\n",
    "        input: (# of batch, seq_length, 128(output feature))\n",
    "        FC(Dense) - ReLU - Dropout - FC - ReLU - Dropout\n",
    "        output: (# of batch, seq_length, 128(output feature))\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim):\n",
    "        super(Prenet, self).__init__()\n",
    "        self.layer = nn.ModuleList(\n",
    "            [nn.Linear(in_dim, 256)\n",
    "            ,nn.Linear(256, 128)]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for layer in self.layer:\n",
    "            x = self.dropout(F.relu(layer(x)))\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "        prenet - CBHG\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.prenet = Prenet(256)\n",
    "        self.cbhg = EncoderCBHG()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cbhg(self.prenet(x))\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DecoderCBHG(nn.Module):\n",
    "    \"\"\"\n",
    "    Conv1D bank - Max Pooling - Conv1D projection - Conv1D Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, K=8):\n",
    "        super(DecoderCBHG, self).__init__()\n",
    "        #conv1d: (batch_size, Channel, Length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        self.conv1dBank = nn.ModuleList(\n",
    "            [nn.Conv1d(in_dim, 128, k, stride=1, padding=k//2) for k in range(1, K+1)]\n",
    "        )\n",
    "        #-----------------Max pooling------------------#\n",
    "        self.maxPool = nn.MaxPool1d(2, stride=1, padding=1)\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        self.conv1dProjs = nn.ModuleList(\n",
    "            [nn.Conv1d(128 * K, 256, 3, stride=1, padding=1)\n",
    "            ,nn.Conv1d(256, 80, 3, stride=1, padding=1)]\n",
    "        )\n",
    "        #-----------------Highway Net------------------#\n",
    "        self.highwayNet = nn.ModuleList(\n",
    "            [HighwayNet(80) for _ in range(4)]\n",
    "        )\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        self.GRU = nn.GRU(128, 128, bidirectional=True, batch_first=True)\n",
    "        #-------------Batch normalization--------------#\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.bn_proj1 = nn.BatchNorm1d(256)\n",
    "        self.bn_proj2 = nn.BatchNorm1d(80)\n",
    "        #------------Transformation for Highwaynet-----#\n",
    "        self.high_linear = nn.Linear(in_dim, 128)\n",
    "        \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = x.transpose(1, 2) # Shape to: (batch_size, channels, seq_length)\n",
    "        #-----------------Conv1Dbank-------------------#\n",
    "        temp = x.size(-1)\n",
    "        stacked = []\n",
    "        for conv1d in self.conv1dBank:\n",
    "            stacked.append(self.bn(conv1d(x)[:, :, :temp]))\n",
    "        \n",
    "        stacked = torch.cat(stacked, dim=1)\n",
    "        #shape: \n",
    "        #-----------------Max pooling------------------#\n",
    "        y = self.maxPool(stacked)[:, :, :temp]\n",
    "        #---------------Conv1Dprojection---------------#\n",
    "        y = self.bn_proj1(F.relu(self.conv1dProjs[0](y)))\n",
    "        y = self.bn_proj2(self.conv1dProjs[1](y))\n",
    "        #-------------residual connection--------------#\n",
    "        y = y + x\n",
    "        #----------------Highway Net-------------------#\n",
    "        y = y.transpose(1, 2)\n",
    "        y = self.high_linear(y)\n",
    "        for layer in self.highwayNet:\n",
    "            y = F.relu(layer(y))\n",
    "        #--------------Bidirectional GRU---------------#\n",
    "        y, _ = self.GRU(y)\n",
    "        \n",
    "        return y\n",
    "\n",
    "             \n",
    "class AttentionWrapper(nn.Module):\n",
    "    def __init__(self, rnn, use_attention):\n",
    "        super(AttentionWrapper, self).__init__()\n",
    "        self.rnn_cell = rnn\n",
    "        self.attention = use_attention\n",
    "        self.projection_for_decoderRNN = nn.Linear(512, 256, bias=False)\n",
    "    def forward(self, memory, decoder_input, cell_hidden):\n",
    "        \"\"\"\n",
    "        memory = (batch_size, encoder_T, dim)\n",
    "        decoder_input = (batch_size, dim)\n",
    "        cell_hidden (previous time step cell state) = (batch, dim)\n",
    "        \"\"\"\n",
    "        batch_size = memory.size(0)\n",
    "        #cell_input = torch.cat((decoder_input, prev_attention), -1) -- why do we have to concat?\n",
    "        cell_input = decoder_input\n",
    "        query = self.rnn_cell(cell_input, cell_hidden)\n",
    "        #feed into attention\n",
    "        attention_weights = self.attention(query, memory)\n",
    "        #make context vector\n",
    "        attention_weights = F.softmax(attention_weights, dim=-1)\n",
    "        attention_weights = attention_weights.view(batch_size\n",
    "                                ,attention_weights.size(1))\n",
    "        context = torch.bmm(attention_weights.view(batch_size, 1, -1), memory).squeeze(1)\n",
    "        out = self.projection_for_decoderRNN(torch.cat([context, query],dim=-1))\n",
    "        return out, query, attention_weights\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.v = nn.Linear(256,1,bias=False)\n",
    "        self.query_layer = nn.Linear(256,256,bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, query, memory):\n",
    "        \"\"\"\n",
    "        query : (batch, 1 ,dim)\n",
    "        \"\"\"\n",
    "        if query.dim() == 2:\n",
    "            query = query.unsqueeze(1)\n",
    "        attention_weight = self.v(self.tanh(self.query_layer(query) + memory))\n",
    "        return attention_weight\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, spect_dim, r=5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.spect_dim = spect_dim\n",
    "        self.r = r\n",
    "        self.prenet = Prenet(r*spect_dim)\n",
    "        self.attention_RNN = AttentionWrapper(nn.GRUCell(input_size=128, hidden_size =256), BahdanauAttention())\n",
    "        self.decoderRNN = nn.ModuleList(\n",
    "                            [nn.GRUCell(input_size=256,hidden_size=256) for _ in range(2)])\n",
    "        self.spectro_layer = nn.Linear(256,spect_dim*r,bias=False)\n",
    "        self.epsilon = 0.2\n",
    "        self.maximum_step = 1000\n",
    "        return\n",
    "    \n",
    "    def forward(self, memory, target=None):\n",
    "        \"\"\"\n",
    "        if training time, input is given, else input is decoder outputs\n",
    "        input : \n",
    "            memory (encoder_output) = (batch_size, encoder_T, char_dim)\n",
    "            decoder_input = (batch_size, decoder_T, dim)\n",
    "        output:\n",
    "            \n",
    "        \"\"\"\n",
    "        batch_size = memory.size(0)\n",
    "        test = target is None\n",
    "        decoder_T = 0\n",
    "        \n",
    "        #train data를 r 단위로 묶어준 후 T의 크기를 바꾸어준다.\n",
    "        if not test:\n",
    "            target = target.view(batch_size, target.size(1) // self.r, -1)\n",
    "            decoder_T = target.size(1)\n",
    "            target = target.transpose(0,1) #for parallelization\n",
    "            \n",
    "        #2단계 decoderRNN 값 저장할 array\n",
    "        decoderRNN_output = [torch.zeros([batch_size, 256]) for _ in range(len(self.decoderRNN))] \n",
    "        cell_hidden = torch.zeros([batch_size, 256])\n",
    "        \n",
    "        #<GO> Frame\n",
    "        #print(self.r * self.spect_dim)\n",
    "        current_input = torch.zeros([batch_size, self.r*self.spect_dim])\n",
    "        t = 0\n",
    "        targets = []\n",
    "        attention_weights = []\n",
    "        \n",
    "        while (True):\n",
    "            t = t + 1\n",
    "            \n",
    "            #prenet\n",
    "            #(B, spect_dim * r)\n",
    "            #print(current_input.size())\n",
    "            prenet_output = self.prenet(current_input)\n",
    "            #attention\n",
    "            #(B, 256)\n",
    "            attention_output, cell_hidden, attention_weight = self.attention_RNN(memory, prenet_output, cell_hidden)\n",
    "    \n",
    "            #decoder\n",
    "            #(B, spect_dim * r)\n",
    "            for idx in range(2):\n",
    "                decoderRNN_output[idx] = self.decoderRNN[idx](attention_output, decoderRNN_output[idx])\n",
    "                decoderRNN_output[idx] += attention_output\n",
    "                attention_output = decoderRNN_output[idx]\n",
    "            \n",
    "            #projection\n",
    "            targetchar =self.spectro_layer(attention_output)\n",
    "            targets += [targetchar]\n",
    "            attention_weights += [attention_weight]\n",
    "            \n",
    "            #check if this target is the end\n",
    "            if test:\n",
    "                if t > 1 and (targetchar<=self.epsilon).all(): break\n",
    "                if t > self.maximum_step: \n",
    "                    print(\"ERROR : Not converge\")\n",
    "                    break\n",
    "            else:\n",
    "                if t >= decoder_T:\n",
    "                    break\n",
    "                    \n",
    "            #change current input\n",
    "            if test:\n",
    "                current_input = targets[-1]\n",
    "            else:\n",
    "                current_input = target[t-1]\n",
    "                \n",
    "        print(t)\n",
    "        attention_weights = torch.stack(attention_weights).transpose(0,1)\n",
    "        \n",
    "        targets = torch.stack(targets).transpose(0,1).contiguous()\n",
    "        return targets, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessing(nn.Module):\n",
    "    \"\"\"\n",
    "    make post processing data\n",
    "    input : (B, decoder.T, spect_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, spect_dim):\n",
    "        super(PostProcessing, self).__init__()\n",
    "        self.postcbhg = DecoderCBHG(80, K=8)\n",
    "        self.linear = nn.Linear(256, 1025)\n",
    "    def forward(self, batch_size, data):\n",
    "        \"\"\"\n",
    "            make data shape (B, -1, 80)\n",
    "        \"\"\"\n",
    "        output = self.postcbhg(data)\n",
    "        print(\"after postcbhg\", end= \" \")\n",
    "        print(output.size())\n",
    "        output = self.linear(output)\n",
    "        print(\"after postlinear\", end=\" \")\n",
    "        print(output.size())\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class Tacotron(nn.Module):\n",
    "    def __init__(self, vocab_num, input_dim=256, spect_dim=80):\n",
    "        super(Tacotron, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.spect_dim = spect_dim\n",
    "        self.embedding = nn.Embedding(vocab_num, input_dim) #embedding dimension\n",
    "        self.embedding.weight.data.normal_(0,0.3)\n",
    "        self.Encoder = Encoder()\n",
    "        self.Decoder = Decoder(spect_dim, r=5) #write input_dimension\n",
    "        self.PostProcessing = PostProcessing(spect_dim)\n",
    "    def forward(self, inputs, spect_targets=None, r= 5):\n",
    "        \"\"\"\n",
    "        make total model!\n",
    "        input : (B, encoder.T, in_dim)\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"before embedding\", end=\" \")\n",
    "        print(inputs.size())\n",
    "        batch_size = inputs.size(0)\n",
    "        memory = self.embedding(inputs)\n",
    "        print(\"after embedding\", end=\" \")\n",
    "        print(memory.size())\n",
    "        #encoding\n",
    "        #(B, encoder.T, input_dim)\n",
    "        memory = self.Encoder(memory)\n",
    "        print(\"after encoding\", end=\" \")\n",
    "        print(memory.size())\n",
    "        #decoding\n",
    "        #(B, encoder.T, mel_dim * r)\n",
    "        decoder_output, attention_weights = self.Decoder(memory, spect_targets)\n",
    "        \n",
    "        #postprocessing\n",
    "        #(B, decoder.T, 1025)\n",
    "        decoder_output = decoder_output.view(batch_size, -1, self.spect_dim)\n",
    "        wav_output = self.PostProcessing(batch_size, decoder_output)\n",
    "        \n",
    "        return decoder_output, wav_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _pad(seq, max_len):\n",
    "    return np.pad(seq, (0, max_len - len(seq)),\n",
    "                  mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def test_taco():\n",
    "    B, T_out, D_out = 2, 400, 80\n",
    "    r = 5\n",
    "    T_encoder = T_out // r\n",
    "\n",
    "    texts = [\"Thank you very much.\", \"Hello\"]\n",
    "    seqs = [np.array(text_to_sequence(\n",
    "        t, [\"english_cleaners\"]), dtype=np.int) for t in texts]\n",
    "    input_lengths = np.array([len(s) for s in seqs])\n",
    "    max_len = np.max(input_lengths)\n",
    "    seqs = np.array([_pad(s, max_len) for s in seqs])\n",
    "\n",
    "    x = torch.LongTensor(seqs)\n",
    "    y = torch.rand(B, T_out, D_out)\n",
    "    x = Variable(x)\n",
    "    y = Variable(y)\n",
    "\n",
    "    model = Tacotron(vocab_num=len(symbols))\n",
    "\n",
    "    print(\"**Encoder input shape: \", x.size())\n",
    "    print(\"**Decoder input shape: \", y.size())\n",
    "    a, b, c = model(x, spect_targets=y)\n",
    "    print(\"**Mel shape:\", a.size())\n",
    "    print(\"**Linear shape:\", b.size())\n",
    "    print(\"**Attention shape:\", c.size())\n",
    "\n",
    "    assert c.size() == (B, T_encoder, max_len)\n",
    "\n",
    "    # Test greddy decoding\n",
    "    a, b, c = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Encoder input shape:  torch.Size([2, 21])\n",
      "**Decoder input shape:  torch.Size([2, 400, 80])\n",
      "before embedding torch.Size([2, 21])\n",
      "after embedding torch.Size([2, 21, 256])\n",
      "before encoder gru torch.Size([2, 21, 128])\n",
      "after encoding torch.Size([2, 21, 256])\n",
      "80\n",
      "after postcbhg torch.Size([2, 400, 256])\n",
      "after postlinear torch.Size([2, 400, 1025])\n",
      "**Mel shape: torch.Size([2, 400, 80])\n",
      "**Linear shape: torch.Size([2, 400, 1025])\n",
      "**Attention shape: torch.Size([2, 80, 21])\n",
      "before embedding torch.Size([2, 21])\n",
      "after embedding torch.Size([2, 21, 256])\n",
      "before encoder gru torch.Size([2, 21, 128])\n",
      "after encoding torch.Size([2, 21, 256])\n",
      "ERROR : Not converge\n",
      "1001\n",
      "after postcbhg torch.Size([2, 5005, 256])\n",
      "after postlinear torch.Size([2, 5005, 1025])\n"
     ]
    }
   ],
   "source": [
    "test_taco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "185px",
    "left": "998px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
