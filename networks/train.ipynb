{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##train\n",
    "from docopt import docopt\n",
    "\n",
    "# Use text & audio modules from existing Tacotron implementation.\n",
    "import sys\n",
    "from os.path import dirname, join\n",
    "import decoder\n",
    "import encoder\n",
    "import Tacotron\n",
    "from text import text_to_sequence, symbols\n",
    "from util import audio\n",
    "from util.plot import plot_alignment\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as data_utils\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils import data as data_utils\n",
    "import numpy as np\n",
    "\n",
    "from nnmnkwii.datasets import FileSourceDataset, FileDataSource\n",
    "from os.path import join, expanduser\n",
    "\n",
    "import librosa.display\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import tensorboard_logger\n",
    "from tensorboard_logger import log_value\n",
    "from hparams import hparams, hparams_debug_string\n",
    "\n",
    "# Default DATA_ROOT\n",
    "DATA_ROOT = join(expanduser(\"~\"), \"tacotron\", \"training\")\n",
    "\n",
    "fs = hparams.sample_rate\n",
    "\n",
    "global_step = 0\n",
    "global_epoch = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def _pad(seq, max_len):\n",
    "    return np.pad(seq, (0, max_len - len(seq)),\n",
    "                  mode='constant', constant_values=0)\n",
    "\n",
    "\n",
    "def _pad_2d(x, max_len):\n",
    "    x = np.pad(x, [(0, max_len - len(x)), (0, 0)],\n",
    "               mode=\"constant\", constant_values=0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "DocoptLanguageError",
     "evalue": "\"usage:\" (case-insensitive) not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDocoptLanguageError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7953d0d69013>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Command line args:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"--checkpoint-dir\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docopt.py\u001b[0m in \u001b[0;36mdocopt\u001b[1;34m(doc, argv, help, version, options_first)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[0mDocoptExit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprintable_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformal_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDocoptExit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\docopt.py\u001b[0m in \u001b[0;36mprintable_usage\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[0musage_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'([Uu][Ss][Aa][Gg][Ee]:)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musage_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mDocoptLanguageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"usage:\" (case-insensitive) not found.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musage_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mDocoptLanguageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'More than one \"usage:\" (case-insensitive).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocoptLanguageError\u001b[0m: \"usage:\" (case-insensitive) not found."
     ]
    }
   ],
   "source": [
    "class TextDataSource(FileDataSource):\n",
    "    def __init__(self):\n",
    "        self._cleaner_names = [x.strip() for x in hparams.cleaners.split(',')]\n",
    "\n",
    "    def collect_files(self):\n",
    "        meta = join(DATA_ROOT, \"train.txt\")\n",
    "        with open(meta, \"rb\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = list(map(lambda l: l.decode(\"utf-8\").split(\"|\")[-1], lines))\n",
    "        return lines\n",
    "\n",
    "    def collect_features(self, text):\n",
    "        return np.asarray(text_to_sequence(text, self._cleaner_names),\n",
    "                          dtype=np.int32)\n",
    "\n",
    "\n",
    "class _NPYDataSource(FileDataSource):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "\n",
    "    def collect_files(self):\n",
    "        meta = join(DATA_ROOT, \"train.txt\")\n",
    "        with open(meta, \"rb\") as f:\n",
    "            lines = f.readlines()\n",
    "        lines = list(map(lambda l: l.decode(\"utf-8\").split(\"|\")[self.col], lines))\n",
    "        paths = list(map(lambda f: join(DATA_ROOT, f), lines))\n",
    "        return paths\n",
    "\n",
    "    def collect_features(self, path):\n",
    "        return np.load(path)\n",
    "\n",
    "\n",
    "class MelSpecDataSource(_NPYDataSource):\n",
    "    def __init__(self):\n",
    "        super(MelSpecDataSource, self).__init__(1)\n",
    "\n",
    "\n",
    "class LinearSpecDataSource(_NPYDataSource):\n",
    "    def __init__(self):\n",
    "        super(LinearSpecDataSource, self).__init__(0)\n",
    "\n",
    "\n",
    "class PyTorchDataset(object):\n",
    "    def __init__(self, X, Mel, Y):\n",
    "        self.X = X\n",
    "        self.Mel = Mel\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Mel[idx], self.Y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Create batch\"\"\"\n",
    "    r = hparams.outputs_per_step\n",
    "    input_lengths = [len(x[0]) for x in batch]\n",
    "    max_input_len = np.max(input_lengths)\n",
    "    # Add single zeros frame at least, so plus 1\n",
    "    max_target_len = np.max([len(x[1]) for x in batch]) + 1\n",
    "    if max_target_len % r != 0:\n",
    "        max_target_len += r - max_target_len % r\n",
    "        assert max_target_len % r == 0\n",
    "\n",
    "    a = np.array([_pad(x[0], max_input_len) for x in batch], dtype=np.int)\n",
    "    x_batch = torch.LongTensor(a)\n",
    "\n",
    "    input_lengths = torch.LongTensor(input_lengths)\n",
    "\n",
    "    b = np.array([_pad_2d(x[1], max_target_len) for x in batch],\n",
    "                 dtype=np.float32)\n",
    "    mel_batch = torch.FloatTensor(b)\n",
    "\n",
    "    c = np.array([_pad_2d(x[2], max_target_len) for x in batch],\n",
    "                 dtype=np.float32)\n",
    "    y_batch = torch.FloatTensor(c)\n",
    "    return x_batch, input_lengths, mel_batch, y_batch\n",
    "\n",
    "\n",
    "def save_alignment(path, attn):\n",
    "    plot_alignment(attn.T, path, info=\"tacotron, step={}\".format(global_step))\n",
    "\n",
    "\n",
    "def save_spectrogram(path, linear_output):\n",
    "    spectrogram = audio._denormalize(linear_output)\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(spectrogram.T, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, format=\"png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def _learning_rate_decay(init_lr, global_step):\n",
    "    warmup_steps = 4000.0\n",
    "    step = global_step + 1.\n",
    "    lr = init_lr * warmup_steps**0.5 * np.minimum(\n",
    "        step * warmup_steps**-1.5, step**-0.5)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def save_states(global_step, mel_outputs, linear_outputs, attn, y,\n",
    "                input_lengths, checkpoint_dir=None):\n",
    "    print(\"Save intermediate states at step {}\".format(global_step))\n",
    "\n",
    "    # idx = np.random.randint(0, len(input_lengths))\n",
    "    idx = min(1, len(input_lengths) - 1)\n",
    "    input_length = input_lengths[idx]\n",
    "\n",
    "    # Alignment\n",
    "    path = join(checkpoint_dir, \"step{}_alignment.png\".format(\n",
    "        global_step))\n",
    "    # alignment = attn[idx].cpu().data.numpy()[:, :input_length]\n",
    "    alignment = attn[idx].cpu().data.numpy()\n",
    "    save_alignment(path, alignment)\n",
    "\n",
    "    # Predicted spectrogram\n",
    "    path = join(checkpoint_dir, \"step{}_predicted_spectrogram.png\".format(\n",
    "        global_step))\n",
    "    linear_output = linear_outputs[idx].cpu().data.numpy()\n",
    "    save_spectrogram(path, linear_output)\n",
    "\n",
    "    # Predicted audio signal\n",
    "    signal = audio.inv_spectrogram(linear_output.T)\n",
    "    path = join(checkpoint_dir, \"step{}_predicted.wav\".format(\n",
    "        global_step))\n",
    "    audio.save_wav(signal, path)\n",
    "\n",
    "    # Target spectrogram\n",
    "    path = join(checkpoint_dir, \"step{}_target_spectrogram.png\".format(\n",
    "        global_step))\n",
    "    linear_output = y[idx].cpu().data.numpy()\n",
    "    save_spectrogram(path, linear_output)\n",
    "\n",
    "\n",
    "def train(model, data_loader, optimizer,\n",
    "          init_lr=0.002,\n",
    "          checkpoint_dir=None, checkpoint_interval=None, nepochs=None,\n",
    "          clip_thresh=1.0):\n",
    "    model.train()\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "    linear_dim = model.linear_dim\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    global global_step, global_epoch\n",
    "    while global_epoch < nepochs:\n",
    "        running_loss = 0.\n",
    "        for step, (x, input_lengths, mel, y) in tqdm(enumerate(data_loader)):\n",
    "            # Decay learning rate\n",
    "            current_lr = _learning_rate_decay(init_lr, global_step)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = current_lr\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Sort by length\n",
    "            sorted_lengths, indices = torch.sort(\n",
    "                input_lengths.view(-1), dim=0, descending=True)\n",
    "            sorted_lengths = sorted_lengths.long().numpy()\n",
    "\n",
    "            x, mel, y = x[indices], mel[indices], y[indices]\n",
    "\n",
    "            # Feed data\n",
    "            x, mel, y = Variable(x), Variable(mel), Variable(y)\n",
    "            if use_cuda:\n",
    "                x, mel, y = x.cuda(), mel.cuda(), y.cuda()\n",
    "            mel_outputs, linear_outputs, attn = model(\n",
    "                x, mel, input_lengths=sorted_lengths)\n",
    "\n",
    "            # Loss\n",
    "            mel_loss = criterion(mel_outputs, mel)\n",
    "            n_priority_freq = int(3000 / (fs * 0.5) * linear_dim)\n",
    "            linear_loss = 0.5 * criterion(linear_outputs, y) \\\n",
    "                + 0.5 * criterion(linear_outputs[:, :, :n_priority_freq],\n",
    "                                  y[:, :, :n_priority_freq])\n",
    "            loss = mel_loss + linear_loss\n",
    "\n",
    "            if global_step > 0 and global_step % checkpoint_interval == 0:\n",
    "                save_states(\n",
    "                    global_step, mel_outputs, linear_outputs, attn, y,\n",
    "                    sorted_lengths, checkpoint_dir)\n",
    "                save_checkpoint(\n",
    "                    model, optimizer, global_step, checkpoint_dir, global_epoch)\n",
    "\n",
    "            # Update\n",
    "            loss.backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm(\n",
    "                model.parameters(), clip_thresh)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logs\n",
    "            log_value(\"loss\", float(loss.data[0]), global_step)\n",
    "            log_value(\"mel loss\", float(mel_loss.data[0]), global_step)\n",
    "            log_value(\"linear loss\", float(linear_loss.data[0]), global_step)\n",
    "            log_value(\"gradient norm\", grad_norm, global_step)\n",
    "            log_value(\"learning rate\", current_lr, global_step)\n",
    "\n",
    "            global_step += 1\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "        averaged_loss = running_loss / (len(data_loader))\n",
    "        log_value(\"loss (per epoch)\", averaged_loss, global_epoch)\n",
    "        print(\"Loss: {}\".format(running_loss / (len(data_loader))))\n",
    "\n",
    "        global_epoch += 1\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, step, checkpoint_dir, epoch):\n",
    "    checkpoint_path = join(\n",
    "        checkpoint_dir, \"checkpoint_step{}.pth\".format(global_step))\n",
    "    torch.save({\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"global_step\": step,\n",
    "        \"global_epoch\": epoch,\n",
    "    }, checkpoint_path)\n",
    "    print(\"Saved checkpoint:\", checkpoint_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = docopt(__doc__)\n",
    "    print(\"Command line args:\\n\", args)\n",
    "    checkpoint_dir = args[\"--checkpoint-dir\"]\n",
    "    checkpoint_path = args[\"--checkpoint-path\"]\n",
    "    data_root = args[\"--data-root\"]\n",
    "    if data_root:\n",
    "        DATA_ROOT = data_root\n",
    "\n",
    "    # Override hyper parameters\n",
    "    hparams.parse(args[\"--hparams\"])\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Input dataset definitions\n",
    "    X = FileSourceDataset(TextDataSource())\n",
    "    Mel = FileSourceDataset(MelSpecDataSource())\n",
    "    Y = FileSourceDataset(LinearSpecDataSource())\n",
    "\n",
    "    # Dataset and Dataloader setup\n",
    "    dataset = PyTorchDataset(X, Mel, Y)\n",
    "    data_loader = data_utils.DataLoader(\n",
    "        dataset, batch_size=hparams.batch_size,\n",
    "        num_workers=hparams.num_workers, shuffle=True,\n",
    "        collate_fn=collate_fn, pin_memory=hparams.pin_memory)\n",
    "\n",
    "    # Model\n",
    "    model = Tacotron(vocab_num=len(symbols),\n",
    "                     input_dim=256,\n",
    "                     spect_dim=hparams.num_mels,\n",
    "                     )\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=hparams.initial_learning_rate, betas=(\n",
    "                               hparams.adam_beta1, hparams.adam_beta2),\n",
    "                           weight_decay=hparams.weight_decay)\n",
    "\n",
    "    # Load checkpoint\n",
    "    if checkpoint_path:\n",
    "        print(\"Load checkpoint from: {}\".format(checkpoint_path))\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "        try:\n",
    "            global_step = checkpoint[\"global_step\"]\n",
    "            global_epoch = checkpoint[\"global_epoch\"]\n",
    "        except:\n",
    "            # TODO\n",
    "            pass\n",
    "\n",
    "    # Setup tensorboard logger\n",
    "    tensorboard_logger.configure(\"log/run-test\")\n",
    "\n",
    "    print(hparams_debug_string())\n",
    "\n",
    "    # Train!\n",
    "    try:\n",
    "        train(model, data_loader, optimizer,\n",
    "              init_lr=hparams.initial_learning_rate,\n",
    "              checkpoint_dir=checkpoint_dir,\n",
    "              checkpoint_interval=hparams.checkpoint_interval,\n",
    "              nepochs=hparams.nepochs,\n",
    "              clip_thresh=hparams.clip_thresh)\n",
    "    except KeyboardInterrupt:\n",
    "        save_checkpoint(\n",
    "            model, optimizer, global_step, checkpoint_dir, global_epoch)\n",
    "\n",
    "    print(\"Finished\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
